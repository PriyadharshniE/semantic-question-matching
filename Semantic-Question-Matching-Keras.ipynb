{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic-Question-Matching-Keras\n",
    "\n",
    "You can download data from: http://qim.ec.quoracdn.net/quora_duplicate_questions.tsv \n",
    "\n",
    "Dataset info: https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs \n",
    "\n",
    "Blog post about Quora model: https://engineering.quora.com/Semantic-Question-Matching-with-Deep-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import sqmutils.data_utils as du\n",
    "import time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline \n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "\n",
    "pathToDataset = \"/home/elkhand/datasets/Quora/data/quora_duplicate_questions.tsv\"\n",
    "#embedding_path = \"/home/elkhand/datasets/glove-vectors/glove.twitter.27B.100d.txt\"\n",
    "#embedding_path = \"/home/elkhand/datasets/glove-vectors/glove.840B.300d.txt\"\n",
    "# https://fasttext.cc/docs/en/pretrained-vectors.html\n",
    "embedding_path = \"/home/elkhand/datasets/fasttext/wiki.en.vec\"\n",
    "train_dataset_path = pathToDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(pathToDataset, sep='\\t', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train/dev/test set\n",
    "- train 98%\n",
    "- dev 1%\n",
    "- test 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config\n",
      " {'train_dataset_path': '/home/elkhand/datasets/Quora/data/quora_duplicate_questions.tsv', 'test_size': 0.2, 'val_size': 0.2, 'max_seq_len': 32, 'embedding_dimension': 300, 'batch_size': 2048, 'nb_epochs': 100, 'recurrent_dropout': 0.3, 'dropout': 0.3, 'seed': 7, 'is_debug_on': False} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " trainDataset Label distribution:  is_duplicate\n",
      "0    163215\n",
      "1     95528\n",
      "Name: is_duplicate, dtype: int64 \n",
      "\n",
      "\n",
      " valDataset Label distribution:  is_duplicate\n",
      "0    40804\n",
      "1    23882\n",
      "Name: is_duplicate, dtype: int64 \n",
      "\n",
      "\n",
      " testDataset Label distribution:  is_duplicate\n",
      "0    51005\n",
      "1    29853\n",
      "Name: is_duplicate, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First split dataset into train(99%) and test(1%)\n",
    "test_size = 0.2#0.01 # 0.2\n",
    "val_size = 0.2 # 0.2\n",
    "config = du.get_config(train_dataset_path, test_size=test_size, val_size=val_size)\n",
    "trainDataset, testDataset = du.create_train_test_split(config)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Second, split train dataset into train (98%) and val (1%) datasets\n",
    "trainDataset, valDataset = du.create_train_test_split_from_df(trainDataset, config, isValSplit=True)\n",
    "\n",
    "\n",
    "print(\"\\n\",\"trainDataset Label distribution: \", trainDataset.groupby('is_duplicate').is_duplicate.count(), \"\\n\")\n",
    "print(\"\\n\",\"valDataset Label distribution: \", valDataset.groupby('is_duplicate').is_duplicate.count() , \"\\n\")\n",
    "print(\"\\n\",\"testDataset Label distribution: \", testDataset.groupby('is_duplicate').is_duplicate.count() , \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>219038</td>\n",
       "      <td>83628</td>\n",
       "      <td>98452</td>\n",
       "      <td>Why do I see questions with basic grammatical ...</td>\n",
       "      <td>Do people see questions that are marked as nee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>319647</td>\n",
       "      <td>78072</td>\n",
       "      <td>89967</td>\n",
       "      <td>Why is there a regulation on the freedom of sp...</td>\n",
       "      <td>Is there freedom of speech on Quora?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74389</td>\n",
       "      <td>127489</td>\n",
       "      <td>94446</td>\n",
       "      <td>When Muslims have a baby boy, why do they get ...</td>\n",
       "      <td>How difficult is it for a Hindu boy to marry a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64681</td>\n",
       "      <td>112359</td>\n",
       "      <td>112360</td>\n",
       "      <td>Why is the rate of taxes on vehicles so high i...</td>\n",
       "      <td>What is the import duty on vehicles in Nepal?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>289633</td>\n",
       "      <td>410784</td>\n",
       "      <td>348111</td>\n",
       "      <td>What is the real threat to India from being se...</td>\n",
       "      <td>What makes India secular?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    qid1    qid2                                          question1  \\\n",
       "0  219038   83628   98452  Why do I see questions with basic grammatical ...   \n",
       "1  319647   78072   89967  Why is there a regulation on the freedom of sp...   \n",
       "2   74389  127489   94446  When Muslims have a baby boy, why do they get ...   \n",
       "3   64681  112359  112360  Why is the rate of taxes on vehicles so high i...   \n",
       "4  289633  410784  348111  What is the real threat to India from being se...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  Do people see questions that are marked as nee...             1  \n",
       "1               Is there freedom of speech on Quora?             1  \n",
       "2  How difficult is it for a Hindu boy to marry a...             0  \n",
       "3      What is the import duty on vehicles in Nepal?             0  \n",
       "4                          What makes India secular?             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load embeddings\n",
    "\n",
    "We will be using GloVe twitter 100D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word vectors path /home/elkhand/datasets/fasttext/wiki.en.vec\n",
      "embedding size : 2519371\n",
      "embedding dimension : (300,)\n",
      "Total time passed:  321.93811869621277\n"
     ]
    }
   ],
   "source": [
    "print(\"word vectors path\", embedding_path)\n",
    "start = time.time()\n",
    "w2v = du.load_embedding(embedding_path)\n",
    "end = time.time()\n",
    "print(\"Total time passed: \", (end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Keras to use Tensorflow GPU in the backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "num_cores = 8\n",
    "GPU=True\n",
    "CPU = not GPU\n",
    "\n",
    "if GPU:\n",
    "    num_GPU = 1\n",
    "    num_CPU = 8\n",
    "if CPU:\n",
    "    num_CPU = 8\n",
    "    num_GPU = 0\n",
    "\n",
    "configProto = tf.ConfigProto(intra_op_parallelism_threads=num_cores,\\\n",
    "        inter_op_parallelism_threads=num_cores, allow_soft_placement=True,\\\n",
    "        device_count = {'CPU' : num_CPU, 'GPU' : num_GPU})\n",
    "session = tf.Session(config=configProto)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time passed 105.48406982421875\n",
      "df_train_q1_emb.shape (258743, 32, 300)\n",
      "df_train_q2_emb.shape (258743, 32, 300)\n",
      "df_train_label.shape (258743,)\n",
      "df_val_q1_emb.shape (64686, 32, 300)\n",
      "df_val_q2_emb.shape (64686, 32, 300)\n",
      "df_val_label.shape (64686,)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df_train_q1_emb,df_train_q2_emb, df_train_label  = du.load_dataset(trainDataset,w2v,config)\n",
    "df_val_q1_emb,df_val_q2_emb, df_val_label  = du.load_dataset(valDataset,w2v, config)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time passed\", (end - start))\n",
    "print(\"df_train_q1_emb.shape\",df_train_q1_emb.shape)\n",
    "print(\"df_train_q2_emb.shape\", df_train_q2_emb.shape)\n",
    "print(\"df_train_label.shape\", df_train_label.shape)\n",
    "    \n",
    "print(\"df_val_q1_emb.shape\",df_val_q1_emb.shape)\n",
    "print(\"df_val_q2_emb.shape\", df_val_q2_emb.shape)\n",
    "print(\"df_val_label.shape\", df_val_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config\n",
      " {'train_dataset_path': '/home/elkhand/datasets/Quora/data/quora_duplicate_questions.tsv', 'test_size': 0.2, 'val_size': 0.2, 'max_seq_len': 32, 'embedding_dimension': 300, 'batch_size': 3096, 'nb_epochs': 100, 'recurrent_dropout': 0.3, 'dropout': 0.3, 'seed': 7, 'is_debug_on': False} \n",
      "\n",
      "Total time passed 2.384185791015625e-07\n",
      "df_train_q1_emb.shape (258743, 32, 300)\n",
      "df_train_q2_emb.shape (258743, 32, 300)\n",
      "df_train_label.shape (258743,)\n",
      "df_val_q1_emb.shape (64686, 32, 300)\n",
      "df_val_q2_emb.shape (64686, 32, 300)\n",
      "df_val_label.shape (64686,)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "q1_in (InputLayer)              (None, 32, 300)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "q2_in (InputLayer)              (None, 32, 300)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_14 (LSTM)                  (None, 32, 128)      219648      q1_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_16 (LSTM)                  (None, 32, 128)      219648      q2_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_13 (LSTM)                  (None, 128)          219648      q1_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 4096)         0           lstm_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_15 (LSTM)                  (None, 128)          219648      q2_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 4096)         0           lstm_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8448)         0           lstm_13[0][0]                    \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 lstm_15[0][0]                    \n",
      "                                                                 flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            8449        concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 887,041\n",
      "Trainable params: 887,041\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 258743 samples, validate on 64686 samples\n",
      "Epoch 1/100\n",
      "258743/258743 [==============================] - 66s 253us/step - loss: 0.6167 - acc: 0.6587 - f1: 0.2787 - recall: 0.2142 - precision: 0.4733 - val_loss: 0.5990 - val_acc: 0.6790 - val_f1: 0.5608 - val_recall: 0.5553 - val_precision: 0.5666\n",
      "Epoch 2/100\n",
      "258743/258743 [==============================] - 63s 243us/step - loss: 0.5771 - acc: 0.6974 - f1: 0.4994 - recall: 0.4111 - precision: 0.6423 - val_loss: 0.5668 - val_acc: 0.7072 - val_f1: 0.5666 - val_recall: 0.5187 - val_precision: 0.6246\n",
      "Epoch 3/100\n",
      "258743/258743 [==============================] - 63s 242us/step - loss: 0.5606 - acc: 0.7112 - f1: 0.5306 - recall: 0.4451 - precision: 0.6645 - val_loss: 0.5524 - val_acc: 0.7184 - val_f1: 0.5538 - val_recall: 0.4735 - val_precision: 0.6672\n",
      "Epoch 4/100\n",
      "258743/258743 [==============================] - 62s 241us/step - loss: 0.5495 - acc: 0.7185 - f1: 0.5478 - recall: 0.4641 - precision: 0.6744 - val_loss: 0.5501 - val_acc: 0.7197 - val_f1: 0.6005 - val_recall: 0.5707 - val_precision: 0.6337\n",
      "Epoch 5/100\n",
      "258743/258743 [==============================] - 63s 245us/step - loss: 0.5408 - acc: 0.7246 - f1: 0.5619 - recall: 0.4799 - precision: 0.6819 - val_loss: 0.5380 - val_acc: 0.7278 - val_f1: 0.5507 - val_recall: 0.4521 - val_precision: 0.7048\n",
      "Epoch 6/100\n",
      "258743/258743 [==============================] - 64s 246us/step - loss: 0.5348 - acc: 0.7300 - f1: 0.5723 - recall: 0.4911 - precision: 0.6900 - val_loss: 0.5444 - val_acc: 0.7232 - val_f1: 0.6175 - val_recall: 0.6055 - val_precision: 0.6302\n",
      "Epoch 7/100\n",
      "258743/258743 [==============================] - 64s 248us/step - loss: 0.5290 - acc: 0.7329 - f1: 0.5808 - recall: 0.5024 - precision: 0.6902 - val_loss: 0.5303 - val_acc: 0.7334 - val_f1: 0.5816 - val_recall: 0.5021 - val_precision: 0.6912\n",
      "Epoch 8/100\n",
      "258743/258743 [==============================] - 64s 247us/step - loss: 0.5241 - acc: 0.7358 - f1: 0.5860 - recall: 0.5085 - precision: 0.6959 - val_loss: 0.5423 - val_acc: 0.7235 - val_f1: 0.6241 - val_recall: 0.6220 - val_precision: 0.6263\n",
      "Epoch 9/100\n",
      "258743/258743 [==============================] - 63s 245us/step - loss: 0.5197 - acc: 0.7394 - f1: 0.5948 - recall: 0.5201 - precision: 0.6996 - val_loss: 0.5275 - val_acc: 0.7354 - val_f1: 0.6100 - val_recall: 0.5607 - val_precision: 0.6691\n",
      "Epoch 10/100\n",
      "258743/258743 [==============================] - 63s 245us/step - loss: 0.5136 - acc: 0.7432 - f1: 0.6020 - recall: 0.5272 - precision: 0.7045 - val_loss: 0.5440 - val_acc: 0.7207 - val_f1: 0.6376 - val_recall: 0.6656 - val_precision: 0.6120\n",
      "Epoch 11/100\n",
      "258743/258743 [==============================] - 64s 248us/step - loss: 0.5087 - acc: 0.7464 - f1: 0.6107 - recall: 0.5401 - precision: 0.7052 - val_loss: 0.5281 - val_acc: 0.7341 - val_f1: 0.6284 - val_recall: 0.6093 - val_precision: 0.6490\n",
      "Epoch 12/100\n",
      "258743/258743 [==============================] - 64s 247us/step - loss: 0.5029 - acc: 0.7488 - f1: 0.6157 - recall: 0.5464 - precision: 0.7077 - val_loss: 0.5284 - val_acc: 0.7343 - val_f1: 0.6317 - val_recall: 0.6175 - val_precision: 0.6468\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 13/100\n",
      "258743/258743 [==============================] - 64s 247us/step - loss: 0.4929 - acc: 0.7544 - f1: 0.6264 - recall: 0.5581 - precision: 0.7145 - val_loss: 0.5278 - val_acc: 0.7354 - val_f1: 0.6327 - val_recall: 0.6175 - val_precision: 0.6489\n",
      "Epoch 14/100\n",
      "258743/258743 [==============================] - 64s 247us/step - loss: 0.4883 - acc: 0.7574 - f1: 0.6335 - recall: 0.5685 - precision: 0.7161 - val_loss: 0.5274 - val_acc: 0.7358 - val_f1: 0.6322 - val_recall: 0.6151 - val_precision: 0.6504\n",
      "Epoch 15/100\n",
      "258743/258743 [==============================] - 64s 248us/step - loss: 0.4857 - acc: 0.7583 - f1: 0.6363 - recall: 0.5732 - precision: 0.7157 - val_loss: 0.5290 - val_acc: 0.7360 - val_f1: 0.6334 - val_recall: 0.6178 - val_precision: 0.6499\n",
      "Epoch 16/100\n",
      "258743/258743 [==============================] - 65s 251us/step - loss: 0.4828 - acc: 0.7598 - f1: 0.6393 - recall: 0.5770 - precision: 0.7174 - val_loss: 0.5333 - val_acc: 0.7307 - val_f1: 0.6369 - val_recall: 0.6400 - val_precision: 0.6341\n",
      "Epoch 17/100\n",
      "258743/258743 [==============================] - 64s 249us/step - loss: 0.4801 - acc: 0.7611 - f1: 0.6425 - recall: 0.5816 - precision: 0.7182 - val_loss: 0.5285 - val_acc: 0.7368 - val_f1: 0.6304 - val_recall: 0.6080 - val_precision: 0.6546\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 18/100\n",
      "258743/258743 [==============================] - 63s 245us/step - loss: 0.4753 - acc: 0.7641 - f1: 0.6473 - recall: 0.5868 - precision: 0.7222 - val_loss: 0.5342 - val_acc: 0.7324 - val_f1: 0.6366 - val_recall: 0.6351 - val_precision: 0.6384\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258743/258743 [==============================] - 64s 246us/step - loss: 0.4746 - acc: 0.7647 - f1: 0.6489 - recall: 0.5893 - precision: 0.7224 - val_loss: 0.5341 - val_acc: 0.7323 - val_f1: 0.6365 - val_recall: 0.6352 - val_precision: 0.6381\n",
      "Epoch 20/100\n",
      "258743/258743 [==============================] - 65s 250us/step - loss: 0.4740 - acc: 0.7654 - f1: 0.6507 - recall: 0.5924 - precision: 0.7222 - val_loss: 0.5337 - val_acc: 0.7335 - val_f1: 0.6347 - val_recall: 0.6274 - val_precision: 0.6424\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 21/100\n",
      "258743/258743 [==============================] - 65s 251us/step - loss: 0.4727 - acc: 0.7655 - f1: 0.6499 - recall: 0.5899 - precision: 0.7238 - val_loss: 0.5339 - val_acc: 0.7335 - val_f1: 0.6356 - val_recall: 0.6298 - val_precision: 0.6417\n",
      "Epoch 22/100\n",
      "258743/258743 [==============================] - 65s 251us/step - loss: 0.4726 - acc: 0.7653 - f1: 0.6507 - recall: 0.5923 - precision: 0.7221 - val_loss: 0.5343 - val_acc: 0.7331 - val_f1: 0.6355 - val_recall: 0.6305 - val_precision: 0.6409\n",
      "Epoch 23/100\n",
      "258743/258743 [==============================] - 65s 250us/step - loss: 0.4724 - acc: 0.7650 - f1: 0.6501 - recall: 0.5917 - precision: 0.7217 - val_loss: 0.5345 - val_acc: 0.7330 - val_f1: 0.6358 - val_recall: 0.6314 - val_precision: 0.6404\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Epoch 24/100\n",
      "258743/258743 [==============================] - 65s 250us/step - loss: 0.4719 - acc: 0.7662 - f1: 0.6521 - recall: 0.5938 - precision: 0.7233 - val_loss: 0.5345 - val_acc: 0.7331 - val_f1: 0.6358 - val_recall: 0.6313 - val_precision: 0.6407\n",
      "Epoch 25/100\n",
      "258743/258743 [==============================] - 65s 250us/step - loss: 0.4725 - acc: 0.7646 - f1: 0.6497 - recall: 0.5916 - precision: 0.7208 - val_loss: 0.5348 - val_acc: 0.7328 - val_f1: 0.6359 - val_recall: 0.6321 - val_precision: 0.6399\n",
      "Epoch 26/100\n",
      "258743/258743 [==============================] - 65s 250us/step - loss: 0.4721 - acc: 0.7655 - f1: 0.6514 - recall: 0.5937 - precision: 0.7218 - val_loss: 0.5347 - val_acc: 0.7330 - val_f1: 0.6359 - val_recall: 0.6317 - val_precision: 0.6403\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "Epoch 27/100\n",
      "258743/258743 [==============================] - 65s 250us/step - loss: 0.4725 - acc: 0.7652 - f1: 0.6505 - recall: 0.5920 - precision: 0.7220 - val_loss: 0.5347 - val_acc: 0.7330 - val_f1: 0.6359 - val_recall: 0.6317 - val_precision: 0.6403\n",
      "Epoch 28/100\n",
      "258743/258743 [==============================] - 65s 251us/step - loss: 0.4721 - acc: 0.7659 - f1: 0.6514 - recall: 0.5927 - precision: 0.7232 - val_loss: 0.5347 - val_acc: 0.7330 - val_f1: 0.6359 - val_recall: 0.6316 - val_precision: 0.6405\n",
      "Epoch 29/100\n",
      "207432/258743 [=======================>......] - ETA: 10s - loss: 0.4714 - acc: 0.7659 - f1: 0.6515 - recall: 0.5936 - precision: 0.7222"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Dense\n",
    "from keras.layers import GRU, Bidirectional\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Masking\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "import keras\n",
    "from keras.layers import multiply\n",
    "\n",
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Masking\n",
    "\n",
    "\n",
    "def _build_model(config):\n",
    "    input1 = keras.layers.Input(shape=(config[\"max_seq_len\"],config[\"embedding_dimension\"], ), name='q1_in')\n",
    "    #mask1 = Masking(mask_value=0.0)(input1)\n",
    "    mask1 = input1\n",
    "    lstm1 = LSTM(128, activation=\"relu\")(mask1)\n",
    "    lstm11 = LSTM(128,dropout=config['dropout'], recurrent_dropout=config['recurrent_dropout'], \n",
    "                  activation=\"relu\",return_sequences=True)(mask1)\n",
    "    lstm11 = keras.layers.Flatten()(lstm11)\n",
    "    \n",
    "    input2 = keras.layers.Input(shape=(config[\"max_seq_len\"],config[\"embedding_dimension\"], ), name='q2_in')\n",
    "    #mask2 = Masking(mask_value=0.0)(input2)\n",
    "    mask2 = input2\n",
    "    lstm2 = LSTM(128,activation=\"relu\")(mask2)\n",
    "    lstm22 = LSTM(128,dropout=config['dropout'], recurrent_dropout=config['recurrent_dropout'], \n",
    "                  activation=\"relu\", return_sequences=True)(mask2)\n",
    "    lstm22 = keras.layers.Flatten()(lstm22)\n",
    "    \n",
    "    concatenate = keras.layers.concatenate([lstm1, lstm11, lstm2, lstm22], axis=-1)\n",
    "    \n",
    "    output = Dense(1, activation='sigmoid', name='output')(concatenate)\n",
    "    model = Model(inputs=[input1, input2], outputs=[output])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                  metrics=['accuracy', du.f1, du.recall, du.precision])\n",
    "    model.summary()\n",
    "    plot_model(model, to_file='models/model.png')\n",
    "    return model\n",
    "\n",
    "def _build_model_old(config):\n",
    "    shared_lstm1 = keras.layers.Bidirectional(LSTM(128), merge_mode='concat', weights=None)\n",
    "    shared_lstm2 = keras.layers.Bidirectional(LSTM(128), merge_mode='concat', weights=None)\n",
    "    input1 = keras.layers.Input(shape=(config[\"max_seq_len\"],config[\"embedding_dimension\"], ), name='q1_in')\n",
    "    mask1 = Masking(mask_value=0.0)(input1)\n",
    "    x1 = shared_lstm1(mask1)\n",
    "    \n",
    "    input2 = keras.layers.Input(shape=(config[\"max_seq_len\"],config[\"embedding_dimension\"], ), name='q2_in')\n",
    "    mask2 = Masking(mask_value=0.0)(input2)\n",
    "    x2 = shared_lstm1(mask2)\n",
    "    \n",
    "    x22 = shared_lstm2(mask2)\n",
    "    x11 = shared_lstm2(mask1)\n",
    "    \n",
    "    # Equivalent to subtracted = keras.layers.subtract([x1, x2])\n",
    "    subtracted = keras.layers.Subtract()([x1, x2])\n",
    "    mult = multiply([x1, x2])\n",
    "    dotProduct = keras.layers.dot([x1, x2], axes = -1,  normalize=False)\n",
    "    \n",
    "    \n",
    "    subtracted2 = keras.layers.Subtract()([x11, x22])\n",
    "    mult2 = multiply([x11, x22])\n",
    "    dotProduct2 = keras.layers.dot([x11, x22], axes = -1,  normalize=False)\n",
    "    \n",
    "    concatenate = keras.layers.concatenate([x1,x2, subtracted, mult, dotProduct,\n",
    "                                            subtracted2, mult2, dotProduct2, x22, x11], axis=-1)\n",
    "    \n",
    "    #concatenate = keras.layers.concatenate([x1,x2], axis=-1)\n",
    "    dense1 = Dense(512, activation='relu', name='dense1')(concatenate)\n",
    "    dense2 = Dense(32, activation='relu', name='dense2')(dense1)\n",
    "    output = Dense(1, activation='sigmoid', name='output')(dense2)\n",
    "    model = Model(inputs=[input1, input2], outputs=[output])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                  metrics=['accuracy', du.f1, du.recall, du.precision])\n",
    "    model.summary()\n",
    "    plot_model(model, to_file='models/model.png')\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model():\n",
    "    config = du.get_config(train_dataset_path, test_size=test_size, val_size=val_size)\n",
    "    start = time.time()\n",
    "    #df_train_q1_emb,df_train_q2_emb, df_train_label  = du.load_dataset(trainDataset,w2v,config)\n",
    "    #df_val_q1_emb,df_val_q2_emb, df_val_label  = du.load_dataset(valDataset,w2v, config)\n",
    "    end = time.time()\n",
    "    print(\"Total time passed\", (end - start))\n",
    "    print(\"df_train_q1_emb.shape\",df_train_q1_emb.shape)\n",
    "    print(\"df_train_q2_emb.shape\", df_train_q2_emb.shape)\n",
    "    print(\"df_train_label.shape\", df_train_label.shape)\n",
    "    \n",
    "    print(\"df_val_q1_emb.shape\",df_val_q1_emb.shape)\n",
    "    print(\"df_val_q2_emb.shape\", df_val_q2_emb.shape)\n",
    "    print(\"df_val_label.shape\", df_val_label.shape)\n",
    "    model = _build_model(config)\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                  factor=0.2, \n",
    "                                  patience=3, \n",
    "                                  #min_lr=0.000001,\n",
    "                                  verbose=1)\n",
    "    \n",
    "    #filepath=\"model/adidas-may-29.h5\"\n",
    "    #checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=15)#10\n",
    "    callback_list = [reduce_lr, early_stopping] # , early_stopping\n",
    "    #config['nb_epochs'] = 10\n",
    "    history = model.fit(x=[df_train_q1_emb, df_train_q2_emb],\n",
    "                  y=df_train_label, \n",
    "                  batch_size=config['batch_size'], \n",
    "                  epochs=config['nb_epochs'], \n",
    "                  verbose=1, \n",
    "                  validation_data = ([df_val_q1_emb,df_val_q2_emb], df_val_label),\n",
    "                  callbacks=callback_list)#\n",
    "    return history \n",
    "\n",
    "start = time.time()\n",
    "history = train_model() \n",
    "end = time.time()\n",
    "print(\"Total time\", (end - start))\n",
    "du.plot_model_accuracy(history,modelDir=\"models/\", hasF1=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [OLD] Train and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _build_model(num_of_classes, config): \n",
    "#     model = Sequential()\n",
    "#     model.add(Masking(mask_value=0., input_shape=(None, config['embedding_dimension'])))\n",
    "#     model.add(Bidirectional(GRU(config['hidden_layer_dim'], return_sequences=True, \\\n",
    "#                 dropout=config['dropout'], recurrent_dropout=config['recurrent_dropout']), merge_mode='concat'))\n",
    "#     model.add(Bidirectional(GRU(config['hidden_layer_dim'], dropout=config['dropout'],\\\n",
    "#                                 recurrent_dropout=config['recurrent_dropout']), merge_mode='concat'))\n",
    "#     model.add(Dense(num_of_classes, activation='softmax'))\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     return model\n",
    "       \n",
    "# def train_model(X_train, y_train, X_val, y_val, num_of_classes, config):\n",
    "#     print('X_train shape : %s' % (X_train.shape,))\n",
    "#     print('y_train shape : %s' % (y_train.shape,))\n",
    "#     print('X_val shape : %s' % (X_val.shape,))\n",
    "#     print('y_val shape : %s' % (y_val.shape,))\n",
    "#     print('number of classes : %d' % num_of_classes) \n",
    "#     model = _build_model(num_of_classes, config)\n",
    "#     reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "#                                   factor=0.2, \n",
    "#                                   patience=5, \n",
    "#                                   min_lr=0.001)\n",
    "#     # checkpoint\n",
    "#     filepath=\"model/adidas-may-29.h5\"\n",
    "#     checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=25)#10\n",
    "#     callback_list = [reduce_lr, checkpoint] # , early_stopping\n",
    "#     history = model.fit(x=X_train,\n",
    "#                   y=y_train, \n",
    "#                   batch_size=config['batch_size'], \n",
    "#                   epochs=config['nb_epochs'], \n",
    "#                   verbose=1, \n",
    "#                   validation_data = (X_val, y_val),\n",
    "#                   shuffle=True,\n",
    "#                   callbacks=callback_list)#\n",
    "    \n",
    "#     val_acc_list = history.history['val_acc']\n",
    "#     best_val_acc =  max(val_acc_list)\n",
    "#     filename = \"intent\" \n",
    "#     filename = \"model/\" + dt.generate_model_name(filename, best_val_acc) + \".h5\"\n",
    "#     os.rename(filepath, filename)\n",
    "#     return history\n",
    "\n",
    "# def train_helper(dfTrain, dfVal, config, shouldShuffleTrainDataset=True):\n",
    "# #     class_to_index = {}\n",
    "# #     index_to_class = {}\n",
    "# #     dfTrain = shuffle(dfTrain)\n",
    "# #     X_train, y_train_index, num_of_classes, class_to_index, index_to_class = dt.load_dataset_StratifiedKFold(dfTrain, w2v, config, class_to_index, index_to_class)\n",
    "# #     y_train = dt.convert_index_to_one_hot(y_train_index, num_of_classes) \n",
    "        \n",
    "# #     print(\"dfTrain.head(10) \\n\", dfTrain.head(10))\n",
    "# #     print(\"dfTrain.tail(10) \\n\", dfTrain.tail(10))\n",
    "# #     print(\"\\n\",\"Train label distribution: \\n\",dfTrain.groupby('label').label.count())\n",
    "# #         print(\"num_of_classes\", num_of_classes)\n",
    "# #         print(\"class_to_index\", class_to_index)\n",
    "# #         print(\"index_to_class\", index_to_class)\n",
    "        \n",
    "# #     print(\"dfVal.head(10)\",dfVal.head(10))\n",
    "# #     print(\"dfVal.tail(10)\",dfVal.tail(10))\n",
    "        \n",
    "# #     X_val, y_val_index, _, _, _ = dt.load_dataset_StratifiedKFold(dfVal, w2v, config, class_to_index, index_to_class)\n",
    "# #     y_val = dt.convert_index_to_one_hot(y_val_index, num_of_classes) \n",
    "# #     print(\"\\n\",\"Val label distribution: \",dfVal.groupby('label').label.count())\n",
    "        \n",
    "#     # Train model\n",
    "#     history = train_model(X_train, y_train, X_val, y_val, num_of_classes, config)\n",
    "#     val_acc_list = history.history['val_acc']\n",
    "#     best_val_acc =  max(val_acc_list)\n",
    "#     return [history, best_val_acc]\n",
    "\n",
    "\n",
    "# def predict(w2v):\n",
    "#     model = keras.models.load_model('model/intent_model_ricodataset.h5')\n",
    "#     sentence = \"www.google.com\"\n",
    "#     X_train = []\n",
    "#     X_train.append(get_sequence_embedding(sentence.split(\" \"),w2v, max_seq_len))\n",
    "#     X_train = np.array(X_train)\n",
    "#     print(X_train.shape)\n",
    "#     result = model.predict(X_train)\n",
    "#     print(result)\n",
    "#     print(index_to_class)\n",
    "#     for i in index_to_class:\n",
    "#         print(\"%s : %.3f%%\" % (index_to_class[i], result[0][i] * 100))\n",
    "\n",
    "# def text_pre_processing(document):\n",
    "#     document = text.text_to_word_sequence(document, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\'')\n",
    "#     print(document)\n",
    "#     return document\n",
    "\n",
    "\n",
    "# def get_config():\n",
    "#     conf = {}\n",
    "#     conf[\"embedding_dimension\"] = 100# 300 #100\n",
    "#     conf[\"max_seq_len\"] = 40\n",
    "#     conf[\"dropout\"] = 0.3\n",
    "#     conf[\"recurrent_dropout\"] = 0.3\n",
    "#     conf[\"hidden_layer_dim\"] = 40\n",
    "#     conf[\"batch_size\"] = 40\n",
    "#     conf[\"nb_epochs\"] = 100 #300\n",
    "#     print(\"config\\n\",conf,\"\\n\")\n",
    "#     return conf\n",
    "    \n",
    "\n",
    "# def main():\n",
    "#     config = get_config()\n",
    "#     if w2v is not None:\n",
    "#         print('embedding size : %d' % len(w2v))\n",
    "#         print('embedding dimension : %s' % (w2v['apple'].shape,))\n",
    "#         print(\"Sample words from word2vec: \", list(w2v.keys())[:10], list(w2v.keys())[-10:])\n",
    "# #         history, best_val_acc = train_helper(dfTrain, dfVal, config)\n",
    "# #         pt.plot_model_accuracy(history,\"model/\", isF1Enabled)\n",
    "# #         print(\"best_val_acc\",best_val_acc)\n",
    "#     # predict()\n",
    "#     # text_pre_processing(\"hello&nbsp;hi\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # execute only if run as a script\n",
    "#     main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
